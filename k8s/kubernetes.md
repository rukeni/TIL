# Kubernetes

쿠버네티스는 다양한 배포 방식을 지원한다. Deployment, StatefulSets, DaemonSet, Job, CronJob등

[http://sculove.github.io/blog/2018/01/18/javascriptflow/](http://sculove.github.io/blog/2018/01/18/javascriptflow/)

## 쿠버네티스 핵심 개념

### Desired State

 쿠버네티스에서 가장 중요한 것은 desired state - 원하는 상태라는 개념이다. 원하는 상태는 **관리자가 바라는 환경**을 의미하고 좀 더 구체적으로는 얼마나 많은 웹서버가 떠 있으면 좋은지, 몇 번 포트로 서비스 하기를 원하는지 등을 말한다.

![Kubernetes%20a513ad6c30754c948b17b929877dbdf5/desired-state.png](Kubernetes%20a513ad6c30754c948b17b929877dbdf5/desired-state.png)

 쿠버네티스는 복잡하고 다양한 작업을 하지만 자세히 들여다보면 현재 상태(current state)를 모니터링하면서 관리자가 설정한 원하는 상태를 유지하려고 내부적으로 이런저런 작업을 하는 로직을 가지고 있다. 현재 상태를 변경하는 작업은 **명령(imperative)**이고 현재 상태를 유지시키려고 노력하는 작업은 **선언(declarative)**이라고 한다.

### Kubernetes Object

 쿠버네티스는 상태를 관리하기 위한 대상을 오브젝트로 정의한다. 기본적으로 수십 가지 오브젝트를 제공하고 새로운 오브젝트를 추가하기가 매우 쉽기 때문에 확장성이 좋다. 주요 오브젝트는 다음과 같다.

### Pod

![Kubernetes%20a513ad6c30754c948b17b929877dbdf5/pod.png](Kubernetes%20a513ad6c30754c948b17b929877dbdf5/pod.png)

 쿠버네티스에서 배포할 수 있는 가장 작은 단위로 한 개 이상의 컨테이너와 스토리지, 네트워크 속성을 가진다. Pod에 속한 컨테이너는 스토리지와 네트워크를 공유하고 서로 localhost로 접근할 수 있다. 컨테이너를 하나만 사용하는 경우도 반드시 Pod으로 감싸서 관리한다.

### ReplicaSet

![Kubernetes%20a513ad6c30754c948b17b929877dbdf5/replicaset.png](Kubernetes%20a513ad6c30754c948b17b929877dbdf5/replicaset.png)

 Pod을 여러 개(한 개 이상) 복제하여 관리하는 오브젝트이다. Pod을 생성하고 개수를 유지하려면 반드시 ReplicaSet을 사용해야 한다. ReplicaSet은 복제할 개수, 개수를 체크할 라벨 선택자, 생성할 Pod의 설정값(템플릿)등을 가지고 있습니다. 직접적으로 ReplicaSet을 사용하기보다는 Deployment등 다른 오브젝트에 의해서 사용되는 경우가 많다.

### Service

 네트워크와 관련된 오브젝트이다. Pod의 외부 네트워크와 연결해주고 여러 개의 Pod을 바라보는 내부 로드 밸런서를 생성할 때 사용한다. 내부 DNS에 서비스 이름을 도메인으로 등록하기 때문에 서비스 디스커버리 역할도 한다.

### Volume

 저장소와 관련된 오브젝트이다. 호스트 디렉토리를 그대로 사용할 수도 있고 EBS같은 스토리지를 동적으로 생성하여 사용할 수도 있다. 사실상 인기 있는 대부분의 저장 방식을 지원한다.

### Object Spec - YAML

> apiVersion: v1
kind: Pod
metadata:
    name: example
spec:
    containers:
    - name: busybox
        image: busybox:1.25
> 

 오브젝트의 명세는 YAML 파일(JSON도 가능하지만 잘 안 씀)로 정의하고 여기에 오브젝트의 종류와 원하는 상태를 입력한다. 이러한 명세는 생성, 조회, 삭제로 관리할 수 있기 때문에 REST API로 쉽게 노출할 수 있다. 접근 권한 설정도 같은 개념을 적용하여 누가 어떤 오브젝트에 어떤 요청을 할 수 있는지 정의할 수 있다.

### 쿠버네티스 배포방식

 쿠버네티스는 어플리케이션을 배포하기 위해 원하는 상태(desired state)를 다양한 오브젝트(object)에 라벨(Label)을 붙여 정의(yaml)하고 API 서버에 전달하는 방식을 사용한다.

- 컨테이너를 2개 배포하는데 80 포트를 오픈다라는 작업이라면
- → 컨테이너를 Pod으로 감싸고 type=app, app=web이라는 라벨을 달아서 type=app, app=web이라는 라벨이 달린 Pod이 2개 있는지 체크하고 없으면 Deployment Spec에 정의된 템플릿을 참고해서 Pod을 생성한다. 그리고 해당 라벨을 가진 Pod을 바라보는 가상의 서비스 IP를 만들고 외부의 80포트를 방금 만든 서비스 IP랑 연결한다.
- 라는 뜻

### 쿠버네티스 아키텍처

 컨테이너는 아주 심플하고 우아하게 동작한다. run을 하면 실행되고 stop을 하면 멈춘다. 서버-클라이언트 구조를 안다면 컨테이너를 관리하는 에이전트를 만들고 중앙에서 API를 이용하여 원격으로 관리하는 모습을 쉽게 그려볼 수 있다.

 쿠버네티스 또한 중앙(Master)에 API서버와 상태 저장소를 두고 각 서버(Node)의 에이전트(kubelet)와 통신하는 단순한 구조이다. 하지만 앞에서 애기한 개념을 여러 모듈로 쪼개어 구현하고 다양한 오픈소스를 사용하기 때문에 설치가 까다롭고 언뜻 구성이 복잡해 보인다.

### 마스터 - 노드 구조

![Kubernetes%20a513ad6c30754c948b17b929877dbdf5/master-node.png](Kubernetes%20a513ad6c30754c948b17b929877dbdf5/master-node.png)

 쿠버네티스는 전체 클러스터를 관리하는 마스터와 컨테이너가 배포되는 노드로 구성되어있다. 모든 명령은 마스터의 API 서버를 호출하고 노드는 마스터와 통신하면서 필요한 작업을 수행한다. 특정 노드의 컨테이너에 명령하거나 로그를 조회할 때도 노드에 직접 명령하는 게 아니라 마스터에 명령을 내리고 마스터가 노드에 접속하여 대신 결과를 응답한다.

### Master

 마스터 서버는 다양한 모듈이 확장성을 고려하여 기능별로 쪼개져 있는 것이 특징 이다. 관리자만 접속할 수 있도록 보안 설정을 해야 하고 마스터 서버가 죽으면 클러스터를 관리할 수 없기 때문에 보통 3대를 구성하여 안정성을 높인다. AWS EKS 같은 경우 마스터를 AWS에서 자체관리하여 안정성을 높였고(마스터에 접속 불가) 개발 환경이나 소규모 환경에선 마스터와 노드를 분리하지 않고 같은 서버에 구성하기도 한다.

### Node

 노드 서버는 마스터 서버와 통신하면서 필요한 Pod을 생성하고 네트워크와 볼륨을 설정한다. 실제 컨테이너들이 생성되는 곳으로 수백, 수천대로 확장할 수 있다. 각각의 서버에 라벨을 붙여 사용목적(GPU 특화, SSD 서버 등)을 정의할 수 있다.

### Kubectl

 API 서버는 json 또는 protobuf형식을 이용한 http 통신을 지원한다. 이 방식을 그대로 쓰면 불편하므로 보통 kubectl 이라는 명령행 도구를 사용한다. 앞으로 엄청나게 많이 사용할 것이다. 어떻게 읽어야 할지 난감한데 공식적으로 큐브컨트롤(cube control)이라고 읽지만 큐브씨티엘, 쿱컨트롤, 쿱씨티엘등도 많이 쓰인다.

### Master 구성요소

![Kubernetes%20a513ad6c30754c948b17b929877dbdf5/kubernetes-master.png](Kubernetes%20a513ad6c30754c948b17b929877dbdf5/kubernetes-master.png)

### API 서버 kube-apiserver

 API 서버는 모든 요청을 처리하는 마스터의 핵심 모듈이다. kubectl의 요청뿐 아니라 내부 모듈의 요청도 처리하며 권한을 체크하여 요청을 거부할 수 있다. 실제로 하는 일은 원하는 상태를 key-value 저장소에 저장하고 저장된 상태를 조회하는 매우 단순한 작업이다. Pod을 노드에 할당하고 상태를 체크하는 일은 다른 모듈로 분리되어 있다. 노드에서 실행 중인 컨테이너의 로그를 보여주고 명령을 보내는 등 디버거 역할도 수행한다.

### 분산 데이터 저장소 etcd

 RAFT 알고리즘을 이용한 key-value 저장소이다. 여러 개로 분산하여 복제할 수 있기 때문에 안정성이 높고 속도도 빠른편이다. 단순히 값을 저장하고 읽는 기능 뿐 아니라 watch 기능이 있어 어떤 상태가 변경되면 바로 체크하여 로직을 실행할 수 있다.

클러스터의 모든 설정, 상태 데이터는 여기 저장되고 나머지 모듈은 stateless하게 동작하기 때문에 etcd만 잘 백업해두면 언제든지 클러스터를 복구할 수 있다. etcd는 오직 API 서버와 통신하고 다른 모듈은 API 서버를 거쳐 etcd 데이터 접근한다. k3s 같은 초 경량 쿠버네티스 배포판에서는 etcd 대신 sqlite를 사용하기도 한다.

### 스케줄러, 컨트롤러

 API 서버는 요청을 받으면 etcd 저장소와 통신할 뿐 실제로 상태를 바꾸는 건 스케줄러와 컨트롤러이다. 현재 상태를 모니터링하다가 원하는 상태와 다르면 각자 맡은 작업을 수행하고 상태를 갱신한다.

### 스케줄러 kube-scheduler

 스케줄러는 할당되지 않은 Pod을 여러 가지 조건(필요한 자원, 라벨)에 따라 적절한 노드 서버에 할당해주는 모듈이다.

### 큐브 컨트롤러 kube-controller-manager

 큐브 컨트롤러는 다양한 역할을 하는 아주 바쁜 모듈이다. 쿠버네티스에 있는 거의 모든 오브젝트의 상태를 관리한다. 오브젝트별로 철저하게 분업화되어 Deployment는 ReplicaSet을 생성하고 ReplicaSet은 Pod을 생성하고 Pod은 스케줄러가 관리하는 방식이다.

### 클라우드 컨트롤러 cloud-controller-manager

 클라우드 컨트롤러는 AWS, GCE, Azure 등 클라우드에 특화된 모듈이다. 노드를 추가/삭제하고 로드 밸런서를 연결하거나 볼륨을 붙일 수 있다. 각 클라우드 업체에서 인터페이스에 맞춰 구현하면 되기 때문에 확장성이 좋고 많은 곳에서 자체 모듈을 만들어 제공하고 있다.

### 큐블릿 kubelet

 노드에 할당된 Pod의 생명주기를 관리한다. Pod을 생성하고 Pod 안의 컨테이너에 이상이 없는지 확인하면서 주기적으로 마스터에 상태를 전달한다. API 서버의 요청을 받아 컨테이너의 로그를 전달하거나 특정 명령을 대신 수행하기도 한다.

### 프록시 kube-proxy

 큐블릿이 Pod을 관리한다면 프록시는 Pod으로 연결되는 네트워크를 관리한다. TCP, UDP, SCTP 스트림을 포워딩하고 여러 개의 Pod을 라운드로빈 형태로 묶어 서비스를 제공할 수 있다. 초기에는 kube-proxy 자체가 프록시 서버로 동작하면서 실제 요청을 프록시 서버가 받고 각 Pod에 전달해 주었는데 시간이 지나면서 iptables를 설정하는 방식으로 변경되었다. iptables에 등록된 규칙이 많아지면 느려지는 이슈 때문에 IPVS를 지원하기 시작 했다.

### 추상화

 컨테이너는 도커고 도커가 컨테이너라고 생각해도 무리가 없는 상황이지만 쿠버네티스는 CRI(Container runtime interface)를 구현한 다양한 컨테이너 런타임을 지원한다. containerd, rkt, CRI-O 등

### 하나의 Pod이 생성되는 과정

위에서 이야기한 조각을 하나하나 모아서 전체 흐름을 살펴보겠다. 관리자가 어플리케이션 배포를 위해 ReplicaSet을 생성하면 다음과 같은 과정을 거쳐 Pod을 생성한다.

![Kubernetes%20a513ad6c30754c948b17b929877dbdf5/create-replicaset.png](Kubernetes%20a513ad6c30754c948b17b929877dbdf5/create-replicaset.png)

 

흐름을 보면 각 모듈은 서로 통신하지 않고 오직 API서버와 통신하는 것을 알 수 있다. API Server를 통해 etcd에 저장된 상태를 체크하고 현재 상태와 원하는 상태가 다르면 필요한 작업을 수행한다.

### kubectl

- ReplicaSet 명세를 yml파일로 정의하고 kubectl 도구를 이용하여 API 서버에 명령을 전달
- API 서버는 새로운 ReplicaSet Object를 etcd에 저장

### Kube Controller

- Kube Controller에 포함된 ReplicaSet Controller가 ReplicaSet을 감시하다가 ReplicaSet에 정의된 Label Selector 조건을 만족하는 Pod이 존재하는지 체크
- 해당하는 라벨의 Pod이 없으면 ReplicaSet의 Pod 템플릿을 보고 새로운 Pod(no as sign)을 생성. 생성은 역시 API 서버에전달하고 API 서버는 etcd에 저장

### Scheduler

- Scheduler는 할당되지 않은(no assign) Pod이 있는지 체크
- 할당되지 않은 Pod이 있으면 조건이 맞는 Node를 찾아 해당 Pod을 할당

### Kubelet

- Kubelet은 자신의 Node에 할당되었지만 아직 생성되지 않은 Pod이 있는지 체크
- 생성되지 않은 Pod이 있으면 명세를 보고 Pod을 생성
- Pod의 상태를 주기적으로 API 서버에 전달

### 쿠버네티스 POD

 쿠버네티스의 파드는 관리와 네트워킹 목적으로 함께 묶여 있는 하나 이상의 컨테이너 그룹이다. 쿠버네티스 디플로이먼트는 파드의 헬스를 검사해서 파드의 컨테이너가 종료되었다면 재시작해준다.

### 쿠버네티스 클러스터

 쿠버네티스는 서로 연결되어서 **단일 유닛처럼** 동작하는 고가용성의 컴퓨터 클러스터를 상호조정한다. 개별 머신에 얽매이지 않게 된다. 이 것은 새로운 배포 모델로써, 어플리케이션을 개별 호스트에 결합하지 않는 방식으로 패키지할 필요가 있다. 즉, 컨테이너화 해야 한다. 쿠버네티스는 마스터와 노드라는 두가지 형태의 자원으로 구성된다. 마스터는 클러스터를 조정하는 역할을한다. 노드는 어플리케이션을 구동하는 역할이다.

### 쿠버네티스 디플로이먼트

 일단 쿠버네티스 클러스터를 구동시키면, 그 위에 컨테이너화된 어플리케이션을 배포할 수 있다. 그러기 위해서, 쿠버네티스 디플로이먼트 설정을 만들어야 한다. 디플로이먼트는 쿠버네티스의 개별 노드들을 관리한다. 머신의 장애나 정비에 대응할 수 있는 자동 복구 메커니즘은 이에 해당한다.

### Kubectl

 쿠버네티스의 CLI이다. 디플로이먼트를 생성하고 관리한다. Kubectl은 클러스터와 상호 작용하기 위해 쿠버네티스 API를 사용한다. 디플로이먼트를 생성할 때는 레플리카 숫자를 지정해야 한다. 

### 쿠버네티스 파드

 쿠버네티스는 여러분의 어플리케이션 인스턴스에 파드를 생성했다. 파드는 한 개이상의 컨테이너 그룹을 뜻하는 추상적인 단어인데 상대적으로 공유할 것이 많은 자원끼리 묶는다. 볼륨과 같은 공유 스토리지, 클러스터 IP 주소와 같은 네트워킹, 컨테이너 이미지 버전 또는 사용할 특정 포트와 같이 각 컨테이너가 동작하는 방식에 대한 정보를 같이 사용해야할때 파드로 묶는다. **파드는 쿠버네티스 플랫폼 상에서 최소 단위이다.** 쿠버네티스에서 배포를 생성할 때, 컨테이너 내부에서 파드를 함께 생성한다. 각 파드는 스케줄 되어진 노드에게 묶여지게 된다. 그리고 삭제되거나 소멸되기 전까지 그 노드에 유지된다.

### 쿠버네티스 노드

 파드는 언제나 노드 상에서 동작한다. 노드는 쿠버네티스에서 워커 머신을 말하며 클러스터에 따라 가상 또는 물리 머신일 수 있다. 하나의 노드는 여러 개의 파드를 가질 수 있고 쿠버네티스 마스터는 클러스터 내 노드를 통해서 파드에 대한 스케줄링을 자동으로 처리한다. Kubelet은 마스터와 노드간의 통신을 책임진다. 하나의 머신 상에서 동작하는 파드와 컨테이너를 관리한다. 

- kubectl 명령어
    - kubectl get : 자원을 나열한다.
    - kubectl describe : 자원에 대해 상세한 정보를 보여준다.
    - kubectl logs : 파드 내 컨테이너의 로그들을 출력한다.
    - kubectl exec : 파드 내 컨테이너에 대한 명령을 실행한다.
    

### 쿠버네티스 서비스

 파드들은 생명주기를 갖는다. 워커 노드가 죽으면 노드상에서 동작하는 파드들 또한 종료된다. 레플리카 셋은 어플리케이션이 지속적으로 동작할 수 있도록 새로운 파드들의 생성을 통해 동적으로 클러스터를 미리 지정해 둔 상태로 되돌려 줄 수도 있다. 쿠버네티스에서 서비스는 하나의 논리적인 파드 셋과 그 파드들에 접근할 수 있는 정책을 정의하는 추상적 개념이다. 서비스는 종속적인 파드들 사이를 느슨하게 결합되도록 해준다. 서비스는 모든 쿠버네티스 오브젝트들과 같이 YAML 또는 JSON을 이용하여 정의된다. 서비스가 대상으로 하는 파드 셋은 보통 LabelSelector에 의해 결정된다.

- ClusterIP : 클러스터 내에서 내부 IP에 대해 서비스를 노출해준다. 이 방식은 오직 클러스터 내에서만 서비스가 접근될 수 있도록 해준다.
- NodePort : NAT가 이용되는 클러스터 내에서 각각 선택된 노드들의 동일한 포트에 서비스를 노출시켜준다. <NodeIP>:<NodePort>를 이용하여 클러스터 외부로부터 서비스가 접근할 수 있도록 해준다. ClusterIP의 상위 집합이다.
- LoadBalancer : 기존 클라우드에서 외부용 로드밸런서를 생성하고 서비스에 고정된 공인 IP를 할당해준다. NodePort의 상위 집합이다.
- ExternalName : 이름으로 CNAME 레코드를 반환함으로써 임의의 이름을 이용하여 서비스를 노출시켜준다. 프록시는 사용되지 않는다.

 

### 쿠버네티스의 제공 기능

- 서비스 디스커버리와 로드 밸런싱 : 쿠버네티스는 DNS 이름을 사용하거나 자체 IP 주소를 사용하여 컨테이너를 노출할 수 있다. 컨테이너에 대한 트래픽이 많으면 쿠버네티스는 네트워크 트래픽을 로드밸런싱하고 배포하여 배포가 안정적으로 이루어질 수 있다.
- 스토리지 오케스트레이션 : 쿠버네티스를 사용하면 로컬 저장소, 공용 클라우드 공급자 등과 같이 원하는 저장소 시스템을 자동으로 탑재 할 수 있다.
- 자동화된 롤아웃과 롤백 : 쿠버네티스를 사용하여 배포된 컨테이너의 원하는 상태를 서술할 수 있으며 현재 상태를 원하는 상태로 설정한 속도에 따라 변경할 수 있다. 예를 들어, 쿠버네티스를 자동화해서 배포용 새 컨테이너를 만들고 기존 컨테이너를 제거하고 모든 리소스를 새 컨테이너에 적용할 수 있다.
- 자동화된 빈 패킹(bin packing) : 컨테이너화된 작업을 실행하는데 사용할 수 있는 쿠버네티스 클러스터 노드를 제공한다. 각 컨테이너가 필요로 하는 CPU와 메모리(RAM)를 쿠버네티스에게 지시한다. 쿠버네티스는 컨테이너를 노드에 맞추어서 리소스를 가장 잘 사용할 수 있도록 해준다.
- 자동화된 복구(self-healing) : 쿠버네티스는 실패한 컨테이너를 다시 시작하고, 컨테이너를 교체하며, '사용자 정의 상태 검사'에 응답하지 않는 컨테이너를 죽이고 서비스 준비가 끝날 때까지 그러한 과정을 클라이언트에 보여주지 않는다.
- 시크릿과 구성 관리 : 쿠버네티스를 사용하면 암호, OAuth 토큰 및 SSH 키와 같은 중요한 정보를 저장하고 관리 할 수 있다. 컨테이너 이미지를 재구성하지 않고 스택 구성에 비밀을 노출하지 않고도 비밀 및 어플리케이션 구성을 배포 및 업데이트 할 수 있다.

### 쿠버네티스 구조

### 클러스터 구조

- 마스터
    - 클러스터 관리
- 노드
    - 컨테이너가 배포되는 머신
    

### 쿠버네티스 내부 구조

- 쿠버네티스에서는 **내부 구조의 추상적인 단위를 오브젝트**라는 말로 부른다. 오브젝트는 기본 오브젝트, 컨트롤러, 그리고 추가적인 메타 정보로 구성된다.
- 오브젝트 스펙(Object Spec)
    - 오브젝트들은 모두 오브젝트의 특성을 기술한 오브젝트 스펙으로 정의가 되고 커맨드 라인을 통해서 오브젝트 생성시 인자로 전달하여 정의를 하거나 또는 yaml이나 json 파일로 스펙을 정의할 수 있다.
- 기본 오브젝트(Basic Object)
    - 쿠버네티스의 워크로드에 관여하는 오브젝트는 4가지가 있다.
        - Pod
            - 컨테이너화된 어플리케이션
            - 기본적인 배포 단위
            - 컨테이너 별로 배포하는 것이 아니라 Pod단위로 배포한다.
                - Pod끼리는 IP와 Port를 공유한다.(localhost 가능)
                - 디스크 볼륨 공유 가능
        - Service
            - 로드밸런서
            - Pod와 Volume을 이용하여 컨테이너들을 정의한 후, 여러개의 Pod를 서비스하면서 이를 로드밸런서인 Service를 이용하여 하나의 IP와 포트로 묶어서 서비스를 제공한다.
                - Pod의 경우 동적으로 생성되고 자동으로 리스타트 되면서 IP가 자주 바뀌기 때문에 로드밸런서에서 IP를 이용하는 것이 어렵다. 또한 오토 스케일링으로 인하여 Pod가 동적으로 추가 또는 삭제되기 때문에 라벨이라는 개념과 라벨 셀렉터라는 개념을 사용한다.
                - 각 Pod를 생성할때 메타정보로 라벨을 넣음으로써 특정 라벨을 가진 Pod만 서비스에 묶게 된다.
            - 서비스를 정의할때 어떤 Pod를 서비스로 묶을 것인지를 정의하는 일을 라벨 셀렉터라고 한다.
        - Volume
            - 디스크
                - Pod가 시작될때 디폴트로 컨테이너마다 로컬 디스크를 생성한다.
                - 컨테이너가 리스타트되거나 새로 배포될때마다 내용이 유실된다.
                - 로컬 디스크는 영구적이지 않다.
            - 파일을 영속적으로 저장해야 하는 경우의 스토리지를 Volume이라고 한다.
            - 컨테이너의 외장 디스크로 이해하면 쉽다.
        - Namespace
            - 패키지명
            - 논리적인 클러스터 분리이다.
            - CPU와 RAM할당량을 지정할 수 있다.
            - 사용자 별로 접근 권한을 다르게 운영할 수 있다.
            - isolation은 아니기 때문에 다른 네임스페이스 pod와 통신은 가능하다.
                - 통신 불가하게 할 수 있지만 그런 상황이라면 클러스터 자체를 분리하기를 권고
    - 컨트롤러 (Controller)
        - 기본 오브젝트를 생성하고 관리해주는 역할을 한다.
            - Replication Controller
            - Replication Set
            - Daemon Set
            - Job
            - StatefulSet
            - Deployment
        - Replication Controller
            - 지정된 숫자로 Pod를 기동시키고 관리하는 역할
                - 레플리카 수 유지
                - Pod 셀렉터를 이용하여 관리하기 위한 Pod가져오기
                - Pod 추가 기동시 새로운 Pod에 대한 정보 템플릿
            - RC에서 정의한 레플리카 수보다 많으면 추가분의 Pod를 삭제하고 모자르면 새롭게 생성한다.
            - 기존에 생성되어 있는 Pod가 템플릿에 정의된 스펙과 다를지라도 그 Pod를 삭제하지 않는다.
        - ReplicaSet
            - Replication Controller의 새버전
            - 큰 차이는 없고 Replication Controller는 Equality 기반 셀렉터를 사용하고 ReplicaSet은 Set 기반의 셀렉터를 사용한다.
        - Deployment
            - Replication controller와 Replica Set을 좀더 추상화한 개념이다. 실제 운영에서는 Deployment를 사용하게 된다.
        - DaemonSet
            - 일반적인 워크로드를 제외하고 데이터베이스, 배치 작업, 데몬 서버와 같은 형태의 워크로드를 위해 존재한다.
            - 모든 노드에 균등하게 하나씩만 배포 되는 형태이다.
            - 모니터링이나 로그 수집 용도로 많이 사용되며 특정 노드들에만 Pod가 하나씩만 배포 되도록 설정이 가능하다.
        - Job
            - 워크로드 모델중에서 배치나 한번 실행되고 끝나는 형태의 작업
            - 파일 변환 작업을 하거나 주기적으로 ETL 배치 작업을 하는 경우에는 계속 Pod가 떠 있을 필요없이 작업을 할때만 Pod를 띄우면 된다.
            - Job에 의해 관리되는 Pod는 Job이 종료되면 Pod를 같이 종료한다.
        - Cron jobs
            - 주기적으로 Job 컨트롤러를 실행해주는 컨트롤러
        - StatefulSet
            - 데이터베이스와 같이 상태를 가지는 어플리케이션을 관리하기 위한 컨트롤러

- API 서버
    - 쿠버네티스는 모든 명령과 통신을 API를 통해서 하는데 그 중심이 되는 서버가 API서버이다. 쿠버네티스의 모든 기능들을 REST API로 제공하고 그에 대한 명령을 처리한다.
    

### 쿠버네티스 아키텍처

### 마스터

 클러스터 전체를 컨트롤하는 시스템으로 API 서버, 스케줄러, 컨트롤러 매니저, etcd로 구성되어있다.

- Etcd
    - API 서버가 명령을 주고 받는 서버라면, 쿠버네티스 클러스터의 데이터 베이스 역할이 되는 서버는 Etcd이다. etcd는 분산형 키/밸류 스토어 오픈소스로 클러스터의 상태나 설정 정보를 저장한다.
- 스케줄러
    - Pod, 서비스등 각 리소스들을 적절한 노드에 할당하는 역할을 한다.
- 컨트롤러 매니저
    - 컨트롤러들을 생성하고 이를 각 노드에 배포하며 관리한다.
- DNS
    - 쿠버네티스는 리소스의 엔드포인트를 DNS로 맵핑하고 관리한다. Pod나 서비스등은 IP를 배정받는데 동적으로 생성되는 리소스이기 때문에 IP 주소가 그때마다 변경된다. 그래서 리소스에 대한 위치 정보가 필요하고 정보를 알아내는 패턴을 Service discovery 패턴이라고 한다. 쿠버네티스에서는 이를 내부 DNS서버를 두는 방식으로 해 결하였다. 새로운 리소스가 생기면 그 리소스에 대한 IP와 DNS 이름을 등록하여 DNS 이름을 기반으로 리소스에 접근할 수 있도록 한다.

### 노드

 마스터에 의해 명령을 받고 실제 워크로드를 생성하여 서비스 하는 컴포넌트. 노드에는 Kubelet, Kube-proxy, cAdvisor그리고 컨테이너 런타임이 배포된다.

- Kubelet
    - 노드에 배포되는 에이전트이다.
    - 마스터의 API서버와 통신을 하면서 노드가 수행해야 할 명령을 받아서 수행하고 반대로 노드의 상태등을 마스터로 전달하는 역할을 한다.
- Kube-proxy
    - 노드로 들어오는 네트워크 트래픽을 적절한 컨테이너로 라우팅하고 로드밸런싱등 노드로 들어오고 나가는 네트워크 트래픽을 프록시하고 노드와 마스터간의 네트워크 통신을 관리한다.
- Container runtime (컨테이너 런타임)
    - Pod를 통해서 배포된 컨테이너를 실행하는 런타임이다. 컨테이너 런타임은 보통 도커 컨테이너를 생각하기 쉬운데, 도커이외에도 rkt, Hyper container 등 다양한 런타임이 있다.
- cAdvisor
    - 각 노드에서 기동되는 모니터링 에이전트로 노드내에서 가동되는 컨테이너들의 상태와 성능등의 정보를 수집하여 마스터 서버의 API 서버로 전달된다.
    

### 라벨(Label)

 라벨은 키/값 쌍으로 구성된다. 라벨은 사용자가 클러스터내에 객체를 만들때 메타데이터로 붙일 수 있다. 생성된 다음에는 언제든지 수정이 가능하다. 라벨은 쿠버네티스내에서 컨트롤러들이 포드를 관리할 때 자신이 관리해야할 포드를 구분할 수 있는 키 역할을 한다. 라벨만으로 관리 대상을 구분하기 때문에 특정 컨트롤러가 만든 포드라고 하더라도 라벨을 변경하게 되면 인식할 수 없다. 컨트롤러와 포드를 느슨하게 결합하는 이런 특징 때문에 쿠버네티스가 포드들을 관리할때 유연성을 가질 수가 있다. 이런 점을 활용하면 실제 서비스에서 운영중인 포드들 중에서 1개를 임의로 따로 떼어내서 확인하는 것이 가능하다. 이런 기능이 없을 경우 서비스를 운영하는 중에 디버깅이 필요한 경우에는 디버깅용으로 별도의 컨테이너를 띄워서 확인하는게 일반적이다. 하지만 그렇게 했을 경우에는 기존에 발생하던 증상이 재현되지 않아서 확인하기 어려운 경우가 있다. 현재 이슈가 발생한 포드만을 서비스에 영향 없이 따로 떼어내서 확인할 수 있는 건 서비스 운영에 있어서 큰 장점이다. 

 다양하게 라벨을 활용할 수 있다. 노드에도 라벨을 붙일 수 있기 때문에 클러스터내의 노드들을 라벨을 통해서 구분한 다음 특정 라벨을 가진 노드에만 포드를 띄우는 것도 가능하다. 실행하려는 앱의 성격에 따라 SSD 디스크를 가진 노드에만 띄운다던가, GPU 카드를 가진 노드에만 띄운다던가 하는 것이 가능하다. 이런 기능이 없을 경우 서비스를 운영하는 중에 디버깅이 필요한 경우에는 디버깅용으로 별도의 컨테이너를 띄워서 확인하는게 일반적이다. 하지만 그렇게 했을 경우에는 기존에 발생하던 증상이 재현되지 않아서 확인하기 어려운 경우가 있다. 현재 이슈가 발생한 포드만을 서비스에 영향 없이 따로 떼어내서 확인할 수 있다는 건 서비스 운영에 있어서 큰 장점이다. 이 외에도 다양하게 라벨을 활용할 수 있다. 노드에도 라벨을 붙일 수 있기 때문에 클러스터내의 노드들을 라벨을 통해서 구분한 다음 특정 라벨을 가진 노드에만 포드를 띄우는 것도 가능하다. 실행하려는 앱의 성격에 따라 SSD 디스크를 가진 노드에만 띄운다던가, GPU 카드를 가진 노드에만 띄운다던가 하는 것이 가능하다. 라벨의 키는 63자를 넘지 않아야 하고 시작과 끝 문자는 알파벳 대소문자 및 숫자여야하고 중간에는 대시, 언더바, 점, 숫자 등이 올 수 있다. 키 이름 앞에 /로 구분해서 접두어를 사용할 수도 있다. 접두어는 DNS 하위 도메인 형식이어야 하고 점으로 구분할 수 있고 253자를 넘으면 안된다.

### 레이블과 셀렉터

 레이블은 파드와 같은 오브젝트에 첨부된 키와 값의 쌍이다. 레이블은 오브젝트의 특성을 식별하는 데 사용되어 사용자에게 중요하지만, 코어 시스템에 직접적인 의미는 없다. 레이블로 오브젝트의 하위 집합을 선택하고 구성하는데 사용할 수 있다. 레이블은 오브젝트를 생성할 때에 붙이거나 생성 이후에 붙이거나 언제든지 수정이 가능하다. 오브젝트마다 키와 값으로 레이블을 정의할 수 있다. 오브젝트의 키는 고유한 값이어야 한다.

```json
"metadata": {
	"labels": {
		"key1" : "value1",
		"key2" : "value2"
	}
}
```

레이블은 검색에 사용하기 적합하다. 식별되지 않는 정보는 어노테이션으로 기록해야 한다.

### 사용동기

 레이블을 이용하면 사용자가 느슨하게 결합한 방식으로 조직 구조와 시스템 오브젝트를 매핑할 수 있으며 클라이언트에 매핑 정보를 저장할 필요가 없다.

### 구문과 캐릭터 셋

 레이블은 키와 값의 쌍이다. 레이블은 슬래시로 구분되고 접두사와 이름이라는 2개의 구분이 있다. 이름은 63자 미만으로 작성하고 알파벳과 숫자여야 하며 대시 밑줄 점도 사용할 수 있다. 접두사는 선택이다. 접두사를 지정하게 되면 DNS의 하위 도메인으로 해야하며 점과 전체 253자 이하여야 하고 슬래시로 구분하여 둔다. 접두사를 생략하게되면 키 레이블은 개인용으로 간주하고 오브젝트에 자동화된 시스템 구성요소의 접두사는 지정되야 한다.

### 레이블 셀렉터

 이름과 UID와 다르게 레이블은 고유하지는 않다. 일반적으로 많은 오브젝트에 같은 레이블을 가지게 된다. 레이블 셀렉터를 통해 클라이언트와 사용자는 오브젝트를 구분한다. 레이블 셀렉터는 쿠버네티스 코어 그룹의 기본이다. API는 현재 일치성 기준과 집합성 기준이라는 두 종류의 셀렉터를 지원한다. 

### 볼륨

 쿠버네티스 볼륨은 여러가지 종류가 있다. 로컬 디스크 뿐 아니라 NFS, iSCSI, Fiber Channel과 같은 일반적인 외장 디스크 인터페이스는 물론 GlusterFS나 Ceph와 같은 오픈 소스 파일 시스템, AWS EBS, GCP Persistent 디스크와 같은 퍼블릭 클라우드에서 제공되는 디스크, VsphereVolume과 같은 프라이빗 클라우드 솔루션에서 제공하는 디스크 볼륨까지 다양한 볼륨을 지원한다.

- emptyDir
    - Pod가 생성될 때 같이 만들어졌다가 사라지는 임시 볼륨이다.
    - 단, emptyDir의 생명주기는 컨테이너 단위가 아니라 Pod 단위이기 때문에 emptyDir은 삭제 되지 않고 계속 사용이 가능하다.
    - 생성 당시에는 아무 내용이 없기 때문에 emptyDir 이라고 한다.
- hostPath
    - 노드의 로컬 디스크의 경로를 Pod에서 마운트해서 사용한다.
    - 같은 hostPath에있는 볼륨은 여러 Pod 사이에서 공유되어 사용된다.
    - Pod가 삭제 되더라도 hostPath에 있는 파일들은 삭제되지 않고 다른 Pod가 같은 hostPath를 마운트하게 되면 남아 있는 파일을 액세스할 수 있다.
    
- kubeadm
    - 클러스터 빌드 커맨드
- kubelet
    - 모든 머신에서 파드와 컨테이너를 돌아가게 하기위한 컴포넌트
- kubectl
    - 클러스터로 명령하는 커맨드

### 쿠버네티스 DNS

 쿠버네티스에서는 내부에서만 사용가능한 DNS를 설정해 둘 수 있다. 그래서 포드간 통신을 할때나 IP가 아닌 도메인을 설정해 두고 사용할 수 있다. 그렇게해서 한 클러스터에서 사용하던 yaml파일에서 포드간 통신을 도메인으로 설정해 둔다면 별다른 수정 없이 그대로 다른 클러스터로 가져가서 사용하는 것도 가능하다.

### 클러스터내에서 도메인 사용해보기

 쿠버네티스에서 사용하는 내부 도메인은 서비스와 포드에 대해서 사용할 수 있고 일정한 패턴을 가지고 있다. 특정 서비스에 접근하는 도메인은 다음처럼 구성된다. 

> bservice.aname.svc.cluster.local
> 

default라는 네임스페이스에 속한 cpod(10.10.10.10)라는 이름의 포드에 대한 도메인은 다음처럼 구성된다.

> 10-10-10-10.default.pod.cluster.local
> 

cpod의 IP인 10.10.10.10에서 .을 -로변경해서 사용하고 네임스페이스 이름인 default와 연결한 다음 뒤에 pod.cluster.local을 붙여주면 된다. 하지만 이렇게 하면 포드의 ip를 그대로 사용해야 하니까 도메인 네임을 사용하는 장점이 많이 사라지게 된다. 그래서 다른 방법을 사용할 수도 있다. 포드를 실행할때 spec에 hostname과 subdomain을 지정해서 사용할 수 있다. 

> appname.default-subdomain.default.svc.cluster.local
> 

### DNS 구조

 dns역할을 하는 kube-dns역시 클러스터내에서 포드로 실행되고 있다. 포드내에서 DNS에 질의를 할때 어떤 순서로 할것인지 개별 포드마다 지정해 줄 수 있다. 포드의 spec에 dnsPolicy를 이용해서 지정할 수 있다.

- Default: dns 설정을 포드가 실행중인 노드의 설정을 가져와서 사용한다.
- ClusterFirst: cluster.local같은 미리 지정된 클러스터내부 도메인과 일치하지 않는 도메인의 경우에는 클러스터 외부 DNS인 upstream DNS에 질의한다.
- ClusterFirstWithHostNet: 포드를 hostNetwork옵션으로 실행할때 반드시 사용해야 하는 옵션이다.
- None: 포드가 쿠버네티스 클러스터 내부의 DNS 설정을 무시하도록 하는 설정이다. 이 경우에는 포드의 spec에 dnsConfig으로 별도 DNS설정을 해줘야 한다.

다른 포드들에서 도메인 네임을 조회하면 kube-dns쪽으로 질의를 해서 해당 도메인의 IP를 확인한다. 이 때 kube-dns 포드 내부의 DNS캐시인 dnsmasq를 통해서 질의가 이뤄지게 된다. dnsmasq는 kube-dns를 질의하고 거기에서 원하는 결과를 찾을 수 없으면 custom DNS 쪽으로 질의를 하고 거기에도 없으면 다시 upstream DNS쪽으로 질의를 하도록 되어 있다.

### DNS 직접 설정하기

 포드내의 dns설정을 사용자가 직접하는 것도 가능하다. spec에 dnsConfig를 설정해 주면 된다. dnsConfig설정은 dnsPolicy와 함께 쓸수도 있다. dnsPolicy가 none일때는 dnsConfig가 꼭 있어야 한다. dnsConfig에는 3가지 속성들을 설정할 수 있다.

- nameservers: 포드에서 사용할 dns의 ip들이다. dnsPolicy가 None일때는 이 값을 필수로 1개이상 넣어줘야 한다. 최대 3개까지 입력할 수 있다.
- searches: DNS를 검색할때 사용하는 기본 도메인 이름이다. 여기에 svc.cluster.local라고 명시해 두면 a.b.svc.cluster.local이라는 도메인을 사용할때 a.b까지만 입력해도 svc.cluster.local을 포함해서 검색을 해준다. 최대 6개까지 사용할 수 있다.
- options: name과 value를 이용해서 원하는 값을 설정할 수 있다. name은 필수로 있어야 하고 value는 없어도 되는 값이다.

dnsConfig에 설정된 값은 포드의 /etc/resolv.conf에 추가된다. 다음 pod 설정을 dns-test.yaml로 저장한 다음에 적용하고 포드내부의 resolv.conf파일 내용을 확인하면 설정이 어떻게 적용되는지 확인할 수 있다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  namespace: default
  name: dns-test
spec:
  containers:
    - name: dns-test
      image: arisu1000/simple-container-app:latest
  dnsPolicy: ClusterFirst
  dnsConfig:
    nameservers:
      - 8.8.8.8
    searches:
      - default.svc.cluster.local
      - example.com
    options:
      - name: name01
        value: value01
      - name: name02

출처: https://arisu1000.tistory.com/27859 [아리수]
```

[Kubectl](https://www.notion.so/Kubectl-57208a16963f4e45994472999190e5ab)

[iptables](https://www.notion.so/iptables-8eb22f86ebdc43cd9d4cf2b197c1c0cb)

[Service Mesh](https://www.notion.so/Service-Mesh-ecdb9c2d55ad4378a1b2abda12cc732d)

[Helm](https://www.notion.so/Helm-c7c4d815c0484e26ad96b21acf37fc6a)

[Service discovery](https://www.notion.so/Service-discovery-ca6ed7535c4c48b9b069138cddcad8e7)

[EKS](https://www.notion.so/EKS-64c1fc7865c647deaeae30a230976b14)